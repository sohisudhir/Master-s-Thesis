# -*- coding: utf-8 -*-
"""MTL_Bert_Trial1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ITxUNhOFiU3JugoSkgTZu7EzCUs0ROZK
"""


# Setup & Config
import transformers
from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup

import torch
from torch.nn import CrossEntropyLoss, MSELoss
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F

import numpy as np
import pandas as pd
import random
import copy
import csv
import re
import argparse
import os

from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler
import torch.distributed as dist

from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import jaccard_score

from scipy.stats import pearsonr
from scipy.stats import kendalltau
from scipy.stats import spearmanr

RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
# torch.manual_seed(RANDOM_SEED)

"""## Data Exploration

## **MULTI-TASK LEARNING**
"""

class MSLELoss(nn.Module):
  def __init__(self):
    super().__init__()
    self.mse = nn.MSELoss(reduction = 'sum')
        
  def forward(self, pred, actual):
    return self.mse(torch.log(pred + 1.00005), torch.log(actual + 1.00005))

class multitask_model(nn.Module):

  def __init__(self, config): #num_labels, num_emotions, attention_dropout, fc_dropout):
    super(multitask_model, self).__init__()
    self.num_labels = config['abuse_classes']
    self.num_emotions = config['sent_classes']
    self.device = config['device']
    PRE_TRAINED_MODEL_NAME = config['PRE_TRAINED_MODEL_NAME']
    self.b_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)
    self.bert = AdaptedBertModel(self.b_model, True, True, config['bert_dropout'], config['fc_dropout'])
    self.bert_config = self.bert.config
    self.dropout = nn.Dropout(config['fc_dropout'])
    self.main_regression = nn.Linear(self.bert_config.hidden_size, self.num_labels)
    self.aux_classifier = nn.Linear(self.bert_config.hidden_size, self.num_emotions)
    del(self.b_model)

  def forward(self, input_ids, token_type_ids=None, attention_mask=None, main_task=True, targets = None):
    if main_task:
      outputs = self.bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, mode='main_task')
      # pooled_output = self.bert.pooler(outputs)
      pooled_output = outputs.mean(dim = 1)
      pooled_output = self.dropout(pooled_output) 
      logits = self.main_regression(pooled_output)
      # logits = torch.tanh(logits)
      return torch.tanh(logits)
    else:
      outputs = self.bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, mode= 'auxiliary_task')
      # pooled_output = self.bert.pooler(outputs)
      pooled_output = outputs.mean(dim = 1)
      pooled_output = self.dropout(pooled_output) 
      logits = self.aux_classifier(pooled_output)    
      # loss_fct = nn.BCEWithLogitsLoss().to(self.device) 
      # loss = loss_fct(logits.float(), targets.float())
      return logits, torch.sigmoid(logits)
      

class AdaptedBertModel(nn.Module):
  def __init__(self, model, main_task, auxiliary_task, attention_dropout, fc_dropout):
    super().__init__()
    self.embeddings = model.embeddings
    self.encoder = BertEncoder(model.encoder.layer, main_task, auxiliary_task, attention_dropout, fc_dropout)
    self.config = model.config
    self.pooler = model.pooler
  
  def forward(self, input_ids, token_type_ids=None, attention_mask=None,
              mode="main_task"):
    if attention_mask is None:
        attention_mask = torch.ones_like(input_ids)
    if token_type_ids is None:
        token_type_ids = torch.zeros_like(input_ids)

    extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)
    extended_attention_mask = extended_attention_mask.to(
        dtype=next(self.parameters()).dtype
    )
    extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0
    embeddings = self.embeddings(input_ids, token_type_ids)
    embeddings = self.encoder(embeddings, extended_attention_mask, mode)
    return embeddings

# Hard parameter sharing setup : All layers but the last are shared
# Last layer is task-specific

class BertEncoder(nn.Module):

  def __init__(self, layers, main_task, auxiliary_task, attention_dropout, fc_dropout):
    super().__init__()
    self.layers = layers[:-1]
    self.output_attentions = False
    for layer in self.layers:
        layer.attention.self.dropout = nn.Dropout(attention_dropout)
    if main_task:
        self.layer_left = copy.deepcopy(layers[-1])
    if auxiliary_task:
        self.layer_right = copy.deepcopy(layers[-1])

  def forward(self, hidden, attention_mask, mode):
    all_attentions = ()
    for layer in self.layers:
        hidden = layer(hidden, attention_mask)
        if self.output_attentions:
            all_attentions = all_attentions + (hidden[1],)
        hidden = hidden[0]
    if mode == "main_task":
        hidden = self.layer_left(hidden, attention_mask)
    elif mode == "auxiliary_task":
        hidden = self.layer_right(hidden, attention_mask)
    outputs = hidden[0]
    if self.output_attentions:
        outputs = outputs + (all_attentions,)
    return outputs

def evaluation_metrics(preds, targets):
  
  with torch.no_grad():
    tp = torch.zeros(preds.shape[1])
    tn = torch.zeros(preds.shape[1])
    fp = torch.zeros(preds.shape[1])
    fn = torch.zeros(preds.shape[1])
    for n,pred in enumerate(preds):
      for j,pr in enumerate(pred):
        t = targets[n][j]
        if(pr == 0):
          if(t == 0):
            tn[j] += 1
          else:
            fn[j] += 1
        elif(pr == 1):
          if(t == 0):
            fp[j] += 1
          else:
            tp[j] += 1
    #Micro
    num = torch.sum(tp)
    deno_prec = torch.zeros(preds.shape[1])
    deno_rec = torch.zeros(preds.shape[1])
    for j,val in enumerate(deno_prec):
      deno_prec[j] = tp[j] + fp[j]
      deno_rec[j] = tp[j] + fn[j]
    den = torch.sum(deno_prec)
    if(den == 0):
      micro_precision = 0
    else:
      micro_precision = num.item()/den.item()
    den = torch.sum(deno_rec)
    if(den == 0):
      micro_recall = 0
    else:
      micro_recall = num.item()/den.item()
    numerator = 2 * micro_precision * micro_recall
    denominator = micro_precision + micro_recall
    if(denominator == 0):
      micro_f1 = 0
    else:
      micro_f1 = numerator/denominator
    # print(micro_precision, micro_recall, micro_f1)

    #MACRO

    precision = torch.zeros(preds.shape[1])
    recall = torch.zeros(preds.shape[1])
    for j,val in enumerate(precision):
      if(tp[j] + fp[j] == 0):
        precision[j] = 0
      else:
        precision[j] = tp[j]/(tp[j] + fp[j])
      if(tp[j] + fn[j] == 0):
        recall[j] = 0
      else:
        recall[j] = tp[j]/(tp[j] + fn[j])
    f1 =  torch.zeros(preds.shape[1])
    for j,val in enumerate(f1):
      num = 2 * precision[j] * recall[j]
      deno = precision[j] + recall[j]
      if(deno == 0):
        f1[j] = 0
      else:
        f1[j] = num/deno
    macro_precision = torch.mean(precision)
    macro_recall = torch.mean(recall)
    macro_f1 = torch.mean(f1)
    # print(macro_precision, macro_recall, macro_f1)

  return micro_f1, macro_f1

def eval_model(model, data_loader, loc_rank, mode, test = 0):
  
  if(test==1):
    device = "cuda:0"
  else:
    device =  f'cuda:{loc_rank}'
  model = model.to(device)
  model.eval()
  # if(test == 0):
  #   dist.barrier()
  loss_fn_main = nn.MSELoss()
  loss_fn_aux = nn.BCEWithLogitsLoss()

  if(mode == 'main_task'):
    p = []
    t = []
    loss_m = []
    with torch.no_grad():
      for d in data_loader:
        input_ids = d["input_ids"].to(device)
        attention_mask = d["attention_mask"].to(device)
        targets = d["targets"].to(device)
        predictions = model(input_ids=input_ids, token_type_ids = None, attention_mask=attention_mask, main_task = True)
        loss = loss_fn_main(predictions.squeeze(dim = 1), targets)
        p.extend(predictions.squeeze(dim=1).to('cpu').detach().numpy())
        t.extend(targets.to('cpu').detach().numpy())
        loss_m.append(loss.item())
    pear = pearsonr(np.array(t),np.array(p))
    spear = spearmanr(np.array(t),np.array(p))
    tau = kendalltau(np.array(t),np.array(p))
    loss = np.mean(loss_m)
    return pear[0], spear[0], tau[0], loss
  
  elif(mode == 'auxiliary_task'):
    accuracies = []
    loss_a = []
    micro_f1 = []
    macro_f1 = []
    jaccard = []
    with torch.no_grad():
      for d in data_loader:
        input_ids = d["input_ids"].to(device)
        attention_mask = d["attention_mask"].to(device)
        targets = d["targets"].to(device)
        preds_for_loss, predictions = model(input_ids=input_ids, token_type_ids = None, attention_mask=attention_mask, main_task = False, targets = targets)
        # loss_fct = nn.BCEWithLogitsLoss().to(self.device) 
        loss = loss_fn_aux(preds_for_loss.float(), targets.float())
        loss_a.append(loss.item())
        preds = torch.gt(predictions, 0.5).int()
        mic_f1, mac_f1 = evaluation_metrics(preds, targets)
        accuracy = jaccard_score(preds.cpu(),targets.cpu(), average='macro')
        micro_f1.append(mic_f1)
        macro_f1.append(mac_f1)
        jaccard.append(accuracy)
    avg_accuracy = np.mean(jaccard)

    avg_micro_f1 = np.mean(micro_f1)
    avg_macro_f1 = np.mean(macro_f1)
    loss = np.mean(loss_a)
    return avg_micro_f1, avg_macro_f1, loss, avg_accuracy

def train_epoch(model, dataloaders, device, config):
  
  loc_rank = int(config['local_rank'])
  # model = model.to(f'cuda:{loc_rank}')

  model.train()

  if(config['use_ddp']):
    dist.barrier()
  least_loss = 100.0
  data_loader_main = dataloaders['main_train']
  data_loader_aux = dataloaders['aux_train']
  val_data_loader_main = dataloaders['main_val']
  val_data_loader_aux = dataloaders['aux_val']

  loss_fn_main = nn.MSELoss()
  loss_fn_aux = nn.BCEWithLogitsLoss()
  
  device = f'cuda:{loc_rank}'
  optimizer_main = AdamW(model.parameters(), lr = config['lr_main'], weight_decay= 1e-4, correct_bias=False)
  optimizer_aux = AdamW(model.parameters(), lr = config['lr_aux'], weight_decay= 1e-4, correct_bias=False)
  
  total_steps = len(data_loader_main) * config['num_epochs']
  scheduler_main = get_linear_schedule_with_warmup(
  optimizer_main,
  num_warmup_steps=0,
  num_training_steps=total_steps
  )
  total_steps = len(data_loader_aux) * config['num_epochs']
  scheduler_aux = get_linear_schedule_with_warmup(
  optimizer_aux,
  num_warmup_steps=0,
  num_training_steps=total_steps
  )
  coin_flips = []
  #main_task
  for i in range(len(data_loader_main)):
    coin_flips.append(0)
  #auxiliary task
  for i in range(len(data_loader_aux)):
    coin_flips.append(1)

  val_counter = 0
  prev_loss = 100.00
  for epoch in range(config['num_epochs']):
    if(config['use_ddp']):
      # sampler.set_epoch(epoch)
      dataloaders = prepare_data(abuse_files, sent_files, config, epoch)
      data_loader_main = dataloaders['main_train']
      data_loader_aux = dataloaders['aux_train']
      val_data_loader_main = dataloaders['main_val']
      val_data_loader_aux = dataloaders['aux_val']
    if(epoch >= 3):
      # print('Freezing Bert!')
      for param in model.module.bert.encoder.parameters():
        param.requires_grad = False
    if(config['is_master']):
      print("Starting epoch {}".format(epoch))
    random.shuffle(coin_flips)
    loss_m = []
    loss_a = []
    p = []
    t = []
    micro_f1 = [] 
    macro_f1 = []
    accuracies = []
    aux_accuracies = []
    main_dl = iter(data_loader_main)
    aux_dl = iter(data_loader_aux)
    for i in coin_flips:
      if(i == 0):
        #MAIN_TASK
        try:
          d = next(main_dl)
        except:
          main_dl = iter(data_loader_main)
          d = next(main_dl)
        input_ids = d["input_ids"].to(device)
        attention_mask = d["attention_mask"].to(device)
        targets = d["targets"].to(device)
        predictions = model(input_ids=input_ids, token_type_ids = None, attention_mask=attention_mask, main_task = True)
        # optimizer_main.zero_grad()
        loss = loss_fn_main(predictions.squeeze(dim = 1), targets)
        p.extend(predictions.squeeze(dim=1).to('cpu').detach().numpy())
        t.extend(targets.to('cpu').detach().numpy())
        if(config['use_ddp']):
          loss = loss.mean()
        # loss = loss.type(torch.FloatTensor)
        loss_m.append(loss.item())
        loss.backward()
        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer_main.step()
        scheduler_main.step()
        optimizer_main.zero_grad()
        val_counter += 1
      else:
        try:
          d = next(aux_dl)
        except:
          aux_dl = iter(data_loader_aux)
          d = next(aux_dl)
        input_ids = d["input_ids"].to(device)
        attention_mask = d["attention_mask"].to(device)
        targets = d["targets"].to(device)
        preds_for_loss, predictions = model(input_ids=input_ids, token_type_ids = None, attention_mask=attention_mask, main_task = False, targets = targets)
        # loss_fct = nn.BCEWithLogitsLoss().to(self.device) 
        loss = loss_fn_aux(preds_for_loss.float(), targets.float())
        if(config['use_ddp']):
          loss = loss.mean()
        loss_a.append(loss.item())
        # loss = loss * 0.4
        loss.backward()
        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer_aux.step()
        scheduler_aux.step()
        optimizer_aux.zero_grad()
        preds = torch.gt(predictions, 0.5).int()
        mic_f1, mac_f1 = evaluation_metrics(preds, targets)
        jaccard = jaccard_score(preds.cpu(), targets.cpu(), average = "macro")
        micro_f1.append(mic_f1)
        macro_f1.append(mac_f1)
        aux_accuracies.append(jaccard)
        val_counter +=1


    pear = pearsonr(np.array(t),np.array(p))
    spear = spearmanr(np.array(t),np.array(p))
    tau = kendalltau(np.array(t),np.array(p))
    avg_micro_f1 = np.mean(micro_f1)
    avg_macro_f1 = np.mean(macro_f1)

    if(config['is_master']):
      print("MAIN: Epoch {}. Training Pearson {}.Training Spearman {}.Training Kendall {} Training Loss {}".format(epoch, pear[0], spear[0], tau[0], np.mean(loss_m)))
      print("AUX: Epoch {}. Training Micro F1 {}.Training Macro F1 {}.Training Loss {}. Training Accuracy {}".format(epoch, avg_micro_f1, avg_macro_f1, np.mean(loss_a), np.mean(aux_accuracies)))
      pearson, spearman, kendall, loss = eval_model(model, val_data_loader_main, loc_rank, mode = 'main_task')
      print("MAIN: Epoch {}. Validation Pearson {}.Validation Spearman {}. Validation Kendall {}. Validation Loss {}".format(epoch, pearson, spearman, kendall,loss))
      if(loss < least_loss):
        print('Saving best model at epoch', epoch)
        least_loss = loss
        state = {'epoch': epoch+1, 'state_dict': model.state_dict(), 'optimizer_main': optimizer_main.state_dict(),
        'optimizer_aux': optimizer_aux.state_dict()}#, 'scheduler_main': scheduler_main, 'scheduler_aux': scheduler_aux}
        torch.save(model.state_dict(), 'mtl_ddp_best_model.ckpt')

      avg_micro_f1, avg_macro_f1, loss, avg_accuracy = eval_model(model, val_data_loader_aux, loc_rank, mode = 'auxiliary_task')
      if(config['use_ddp']):
        loss = loss.mean()
        avg_micro_f1 = avg_micro_f1.mean()
        avg_macro_f1 = avg_macro_f1.mean()
        avg_accuracy = avg_accuracy.mean()
        print("AUX: Epoch {}.Validation Micro F1 {}.Validation Macro F1 {}. Validation Loss {} Validation Accuracy {}".format(epoch, avg_micro_f1, avg_macro_f1, loss, avg_accuracy))

        state = {'epoch': epoch+1, 'state_dict': model.state_dict(), 'optimizer_main': optimizer_main.state_dict(),
          'optimizer_aux': optimizer_aux.state_dict()}#, 'scheduler_main': scheduler_main, 'scheduler_aux': scheduler_aux}
        print('Saving last model')
        torch.save(model.state_dict(), 'mtl_ddp_last_model.ckpt')

    dist.barrier()

"""## **DATA-PREPARATION**"""

class AbuseDataset(Dataset):

  def __init__(self, reviews, targets, tokenizer, max_len):
    self.reviews = reviews
    self.targets = targets
    self.tokenizer = tokenizer
    self.max_len = max_len
  
  def __len__(self):
    return len(self.reviews)
  
  def __getitem__(self, item):
    review = str(self.reviews[item])
    target = self.targets[item]

    encoding = self.tokenizer.encode_plus(
      review,
      add_special_tokens=True,
      truncation = True,
      max_length=self.max_len,
      return_token_type_ids=False,
      pad_to_max_length=True,
      return_attention_mask=True,
      return_tensors='pt',
    )

    return {
      'review_text': review,
      'input_ids': encoding['input_ids'].flatten(),
      'attention_mask': encoding['attention_mask'].flatten(),
      'targets': torch.tensor(target, dtype=torch.float)
    }

class EmotionDataset(Dataset):

  def __init__(self, tweets, targets, tokenizer, max_len):
    self.tweets = tweets
    self.targets = targets
    self.tokenizer = tokenizer
    self.max_len = max_len
  
  def __len__(self):
    return len(self.tweets)

  def __getitem__(self, item):
    tweet = str(self.tweets[item])
    target = self.targets[item]

    encoding = self.tokenizer.encode_plus(
      tweet,
      add_special_tokens=True,
      truncation = True,
      max_length=self.max_len,
      return_token_type_ids=False,
      pad_to_max_length=True,
      return_attention_mask=True,
      return_tensors='pt',
    )

    return {
      'tweet_text': tweet,
      'input_ids': encoding['input_ids'].flatten(),
      'attention_mask': encoding['attention_mask'].flatten(),
      'targets': torch.tensor(target, dtype=torch.long)
    }

def create_maintask_data_loader(config, df, tokenizer, max_len, batch_size, flag = 0, epoch = 0):
  ds = AbuseDataset(
    reviews=df.comment.to_numpy(),
    targets=df.Score.to_numpy(),
    tokenizer=tokenizer,
    max_len=max_len
  )
  if(config['use_ddp']):
    sampler = DistributedSampler(ds, shuffle = True)
    sampler.set_epoch(epoch)
    return DataLoader(ds,
      batch_size=batch_size,
      sampler = sampler,
      num_workers=4
    )
  else:
    if(flag == 0):
      return DataLoader(ds,
        batch_size=batch_size,
        shuffle = True,
        num_workers=4
      )
    else:
      return DataLoader(ds,
        batch_size=batch_size,
        num_workers=4
      )

def create_auxtask_data_loader(config, df, tokenizer, max_len, batch_size, flag = 0, epoch = 0):
  anger = df.anger.to_numpy()
  anticipation = df.anticipation.to_numpy()
  disgust = df.disgust.to_numpy()
  fear = df.fear.to_numpy()
  joy = df.joy.to_numpy()
  love = df.love.to_numpy()
  optimism = df.optimism.to_numpy()
  pessimism = df.pessimism.to_numpy()
  sadness = df.sadness.to_numpy()
  surprise = df.surprise.to_numpy()
  trust = df.trust.to_numpy()
  emotion = np.stack((anger, anticipation, disgust, fear, joy, love, optimism, pessimism, sadness, surprise, trust), axis = 1)
  ds = EmotionDataset(
    tweets=df.Tweet.to_numpy(),
    targets= emotion,
    tokenizer=tokenizer,
    max_len=max_len
  )

  if(config['use_ddp']):
    sampler = DistributedSampler(ds, shuffle = True)
    sampler.set_epoch(epoch)
    return DataLoader(ds,
      batch_size=batch_size,
      num_workers=4,
      sampler = sampler
    )

  if(flag == 0):
    return DataLoader(ds,
      batch_size=batch_size,
      num_workers=4,
      shuffle = True
    )
  else:
    return DataLoader(ds,
      batch_size=batch_size,
      num_workers=4
    )

def clean_tweets(csvf): 
  fname = 'cleaned_' + csvf
  with open(csvf, 'r', encoding = 'utf-8') as c, open(fname, 'w', encoding = 'UTF-8') as w:
    reader = csv.reader(c, delimiter = '\t')
    writer = csv.writer(w, delimiter = '\t')
    for i,row in enumerate(reader):
      if(i == 0):
        writer.writerow(row)
        continue
      row[1] = row[1].lower()
      row[1] = re.sub(r"#(\w+)", "HASHTAG",  row[1])
      row[1] = re.sub(r"(^|[^@\w])@(\w{1,15})", "_MTN_",  row[1])
      row[1] = re.sub(r"https?://(?:[-\w.]|(?:%[\da-fA-F]{2}))+", "_URL_",  row[1])
      writer.writerow(row)
    
    c.close()
    w.close()

def prepare_data(abuse_files, sent_files, config, epoch = 0):
  
  #Requirements
  BATCH_SIZE = config['batch_size']
  MAX_LEN = config['max_len']
  PRE_TRAINED_MODEL_NAME = config['PRE_TRAINED_MODEL_NAME']
  tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)
  # Arranging data loaders for main task
  a = abuse_files[0]
  b = abuse_files[1]
  c = abuse_files[2]
  df_train = pd.read_csv(a)
  df_val = pd.read_csv(b)
  df_test = pd.read_csv(c)
  # df_train = df_train[0:100]
  # df_val = df_train[0:20]
  # df_test = df_train[0:80]

  # print('Dimensions of abuse file')
  # print(df_train.shape, df_val.shape, df_test.shape)

  data_loader_main = create_maintask_data_loader(config, df_train, tokenizer, MAX_LEN, BATCH_SIZE, 1, epoch)
  val_data_loader_main = create_maintask_data_loader(config, df_val, tokenizer, MAX_LEN, BATCH_SIZE,0, epoch)
  test_data_loader_main = create_maintask_data_loader(config, df_test, tokenizer, MAX_LEN, BATCH_SIZE,0,epoch)

  # Arranging data loaders for auxiliary task -- SEMEVAL2018A
  a = sent_files[0]
  b = sent_files[1]
  c = sent_files[2]
  clean_tweets(a)
  clean_tweets(b)
  clean_tweets(c)
  dist.barrier()
  df_train = pd.read_csv('cleaned_' + a, sep = '\t')
  # df_train = df_train[0:100]
  df_val = pd.read_csv('cleaned_' + b, sep = '\t')
  # df_val = df_val[0:20]
  df_test = pd.read_csv('cleaned_' + c, sep = '\t')
  # df_test = df_test[0:80]
  # print('Dimensions of sentiment file')
  # print(df_train.shape, df_val.shape, df_test.shape)

  data_loader_aux = create_auxtask_data_loader(config, df_train, tokenizer, MAX_LEN, BATCH_SIZE, 1, epoch)
  val_data_loader_aux = create_auxtask_data_loader(config, df_val, tokenizer, MAX_LEN, BATCH_SIZE,0,epoch)
  test_data_loader_aux = create_auxtask_data_loader(config, df_test, tokenizer, MAX_LEN, BATCH_SIZE,0,epoch)

  dataloaders = {'main_train': data_loader_main, 'main_val': val_data_loader_main, 'main_test': test_data_loader_main, 'aux_train': data_loader_aux, 'aux_val': val_data_loader_aux, 'aux_test':  test_data_loader_aux }
  
  return dataloaders

if __name__ == "__main__":

  # os.environ["CUDA_VISIBLE_DEVICES"] = '0,1,2,3'
  # print('fc_dropout bert_dropout', fc_dropout, bert_dropout)
  parser = argparse.ArgumentParser(description="Enter args")
  parser.add_argument('--PRE_TRAINED_MODEL_NAME', default="bert-base-cased", type=str)
  parser.add_argument('--batch_size', default=16, type=int)
  parser.add_argument('--max_len', default=200, type=int)
  parser.add_argument('--abuse_classes', default=1, type=int)
  parser.add_argument('--sent_classes', default=11, type=int)
  parser.add_argument('--bert_dropout', default=0.2, type=float)
  parser.add_argument('--fc_dropout', default=0.4, type=float)
  parser.add_argument('--num_epochs', default=5, type=int)
  parser.add_argument('--lr_main', default=2e-5, type=float)
  parser.add_argument('--lr_aux', default=2e-5, type=float)
  parser.add_argument('--wd', default=1e-4, type=float)
  parser.add_argument('--local_rank', type=int, default=-1, metavar='N', help='Local process rank.')
  parser.add_argument('--use_ddp', type=bool, default=True)
  parser.add_argument('--csv_index', type=int, default=1)

  args = parser.parse_args()
  args.is_master = args.local_rank == 0
  args.device = torch.cuda.device(args.local_rank)

  config = {
      'PRE_TRAINED_MODEL_NAME': 'bert-base-cased',
      'batch_size': args.batch_size,
      'max_len': args.max_len,
      'abuse_classes': args.abuse_classes,
      'sent_classes': args.sent_classes,
      'bert_dropout': args.bert_dropout,
      'fc_dropout': args.fc_dropout,
      'device': torch.cuda.device(args.local_rank),
      'num_epochs': args.num_epochs,
      'lr_main':args.lr_main,
      'lr_aux': args.lr_aux,
      'local_rank':args.local_rank,
      'is_master': args.is_master,
      'use_ddp': args.use_ddp
  }
  if(args.use_ddp):
    dist.init_process_group(backend='nccl', init_method='env://')
    torch.cuda.set_device(args.local_rank)
    torch.cuda.manual_seed_all(RANDOM_SEED)
  abuse_files = ['train.csv', 'val.csv', 'test.csv']#'scores_normal.csv' #'main_cmv_datatset_10000.csv'
  sent_files = ['train.tsv', 'dev.tsv', 'test.tsv']
  dataloaders = prepare_data(abuse_files, sent_files, config)

  model = multitask_model(config)
  device = config['device']
  loc_rank = int(config['local_rank'])
  model = model.to(f'cuda:{loc_rank}')

  if(args.use_ddp):
    model = DDP(
        model,
        device_ids=[args.local_rank],
        output_device=args.local_rank,
        find_unused_parameters=True
    )
  train_epoch(model, dataloaders, device, config)
  if(args.is_master):
    print('End of training....')
  test_data_loader_main = dataloaders['main_test']
  test_data_loader_aux = dataloaders['aux_test']
  if(args.is_master):
    # print('Inside testing 1')
    last_model = multitask_model(config)
    last_model = last_model.to(f'cuda:{loc_rank}')
    best_model = multitask_model(config)
    best_model = best_model.to(f'cuda:{loc_rank}')
    print('lr_main fc_dropout bert_dropout', config['lr_main'], config['fc_dropout'], config['bert_dropout'])

  if(args.is_master):

  	# print('lr main, fc_dropout, bert_dropout: ',config['lr_main'], config['fc_dropout'], config['bert_dropout'])

    print('Loading best model')
    s_dict = torch.load('mtl_ddp_best_model.ckpt')
    from collections import OrderedDict
    new_state_dict = OrderedDict()
    for k, v in s_dict.items():
      name = k[7:] # remove `module.`
      new_state_dict[name] = v
    best_model.load_state_dict(new_state_dict)
    best_model = best_model.to("cuda:0")

    print('Loaded best model')
    pearson, spearman, kendall, loss = eval_model(best_model, test_data_loader_main, loc_rank, mode = 'main_task', test = 1)
    print("MAIN:. Test Pearson {}.Test Spearman {}.Test kendall {}. Test Loss {}".format(pearson, spearman, kendall, loss))
    avg_micro_f1, avg_macro_f1, loss, avg_accuracy = eval_model(best_model, test_data_loader_aux, loc_rank, mode = 'auxiliary_task', test = 1)
    print("AUX: Test Micro F1 {}.Test Macro F1 {}. Test Loss {} Test Accuracy {}".format(avg_micro_f1, avg_macro_f1, loss, avg_accuracy))

    print('Loading last model')
    s_dict = torch.load('mtl_ddp_last_model.ckpt')
    from collections import OrderedDict
    new_state_dict = OrderedDict()
    for k, v in s_dict.items():
      name = k[7:] # remove `module.`
      new_state_dict[name] = v
    last_model.load_state_dict(new_state_dict)
    last_model = last_model.to("cuda:0")
    print('Loaded last model')
    pearson, spearman, kendall, loss = eval_model(last_model, test_data_loader_main, loc_rank, mode = 'main_task', test = 1)
    print("MAIN:. Test Pearson {}.Test Spearman {}.Test kendall {}. Test Loss {}".format(pearson, spearman, kendall, loss))
    avg_micro_f1, avg_macro_f1, loss, avg_accuracy = eval_model(last_model, test_data_loader_aux, loc_rank, mode = 'auxiliary_task', test = 1)
    print("AUX: Test Micro F1 {}.Test Macro F1 {}. Test Loss {} Test Accuracy {}".format(avg_micro_f1, avg_macro_f1, loss, avg_accuracy))

    os.remove('mtl_ddp_best_model.ckpt')
    os.remove('mtl_ddp_last_model.ckpt')
